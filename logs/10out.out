Configuration used :
env: LunarLander-v2
continuous: false
trainer: parallel
network: linear
number_of_repeats: 0
number_of_environments: 4
do_wandb: true
wandb_config:
  project: DeepRL_test
trainers:
  num_episodes: 1000
  batch_size: 64
  gamma: 0.99
  tau: 0.001
  learning_rate: 0.001
  epsilon_start: 0.9
  epsilon_end: 0.1
  epsilon_decay: 0.999
networks:
  layers:
  - 128
  - 128
  - 128

{'num_episodes': 1000, 'batch_size': 64, 'gamma': 0.99, 'tau': 0.001, 'learning_rate': 0.001, 'epsilon_start': 0.9, 'epsilon_end': 0.1, 'epsilon_decay': 0.999}
