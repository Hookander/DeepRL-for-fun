Configuration used :
env: ALE/Breakout-v5
continuous: false
trainer: parallel_ppo
network: cnn_breakout
number_of_environments: 8
do_wandb: true
wandb_config:
  project: DeepRL_test
wrappers:
  RepeatActionV0:
    number_of_repeats: 0
  SpaceInvadersWrapper:
    death_penalty: -30
    missile_penalty: -1
  BreakoutWrapper:
    nothing: 4
  HistoryWrapper:
    n_history: 4
trainers:
  num_episodes: 10000
  batch_size: 64
  gamma: 0.99
  learning_rate: 0.001
  K_epochs: 4
  eps_clip: 0.2
  update_timestep: 200
networks: {}

RepeatActionV0 init
BreakoutWrapper init
HistoryWrapper init
